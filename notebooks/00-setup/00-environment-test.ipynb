{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ Environment Test\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- [ ] Verify all dependencies are installed\n",
    "- [ ] Create your first sentence embeddings\n",
    "- [ ] Visualize embedding space with UMAP\n",
    "- [ ] Experience the \"meaning is geometry\" insight\n",
    "\n",
    "## ‚è±Ô∏è Estimated Time: 15-20 min\n",
    "\n",
    "## üìö Prerequisites\n",
    "- `uv sync` completed successfully\n",
    "- JupyterLab running\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verify Imports\n",
    "\n",
    "Let's make sure all our dependencies are working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import torch\n",
    "print(f\"‚úì NumPy {np.__version__}\")\n",
    "print(f\"‚úì PyTorch {torch.__version__}\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "print(\"‚úì sentence-transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import umap\n",
    "print(\"‚úì matplotlib\")\n",
    "print(\"‚úì plotly\")\n",
    "print(\"‚úì UMAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "import hdbscan\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(\"‚úì HDBSCAN\")\n",
    "print(\"‚úì scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import pandas as pd\n",
    "print(f\"‚úì pandas {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If all cells above ran without errors, your environment is ready!** üéâ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. First Embeddings\n",
    "\n",
    "Let's embed some sentences and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sentence transformer model\n",
    "# First run will download the model (~90MB)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Model loaded! Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some sentences with clear semantic groups\n",
    "sentences = [\n",
    "    # Animals\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"Dogs are loyal companions.\",\n",
    "    \"My pet hamster runs on a wheel.\",\n",
    "    \"Birds fly south for the winter.\",\n",
    "    \n",
    "    # Technology\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"Machine learning models need lots of data.\",\n",
    "    \"The server crashed unexpectedly last night.\",\n",
    "    \"Docker containers simplify deployment.\",\n",
    "    \n",
    "    # Food\n",
    "    \"I love eating pizza on Fridays.\",\n",
    "    \"Fresh vegetables are good for health.\",\n",
    "    \"The chef prepared a delicious meal.\",\n",
    "    \"Coffee keeps me awake in the morning.\",\n",
    "    \n",
    "    # Sports\n",
    "    \"The basketball game was exciting.\",\n",
    "    \"Running a marathon requires training.\",\n",
    "    \"Swimming is great exercise.\",\n",
    "    \"The soccer team won the championship.\",\n",
    "]\n",
    "\n",
    "# Assign labels for visualization\n",
    "labels = [\n",
    "    \"Animals\", \"Animals\", \"Animals\", \"Animals\",\n",
    "    \"Technology\", \"Technology\", \"Technology\", \"Technology\",\n",
    "    \"Food\", \"Food\", \"Food\", \"Food\",\n",
    "    \"Sports\", \"Sports\", \"Sports\", \"Sports\",\n",
    "]\n",
    "\n",
    "print(f\"Prepared {len(sentences)} sentences in {len(set(labels))} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the sentences\n",
    "embeddings = model.encode(sentences, show_progress_bar=True)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Each sentence is now a {embeddings.shape[1]}-dimensional vector!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Check: Similarity\n",
    "\n",
    "Let's verify that similar sentences have similar embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between first sentence and all others\n",
    "first_sentence = sentences[0]\n",
    "similarities = cosine_similarity([embeddings[0]], embeddings)[0]\n",
    "\n",
    "print(f\"Similarity to: \\\"{first_sentence}\\\"\\n\")\n",
    "for sent, sim, label in sorted(zip(sentences, similarities, labels), key=lambda x: -x[1]):\n",
    "    print(f\"  {sim:.3f} [{label:10}] {sent[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice**: The most similar sentences are other animal-related sentences! The embedding captured semantic meaning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize with UMAP\n",
    "\n",
    "Our embeddings are 384-dimensional. Let's project to 2D to see the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions with UMAP\n",
    "reducer = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=5,      # Small because we have few points\n",
    "    min_dist=0.3,\n",
    "    metric='cosine',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "embeddings_2d = reducer.fit_transform(embeddings)\n",
    "print(f\"Reduced to shape: {embeddings_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static plot with matplotlib\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Color by category\n",
    "colors = {'Animals': 'green', 'Technology': 'blue', 'Food': 'orange', 'Sports': 'red'}\n",
    "for label in set(labels):\n",
    "    mask = [l == label for l in labels]\n",
    "    plt.scatter(\n",
    "        embeddings_2d[mask, 0],\n",
    "        embeddings_2d[mask, 1],\n",
    "        c=colors[label],\n",
    "        label=label,\n",
    "        s=100,\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Sentence Embeddings (UMAP Projection)')\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at that!** Similar sentences cluster together. This is the foundation of everything we'll build.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Visualization (Bonus)\n",
    "\n",
    "Let's make it interactive so you can hover over points to see the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for Plotly\n",
    "df = pd.DataFrame({\n",
    "    'x': embeddings_2d[:, 0],\n",
    "    'y': embeddings_2d[:, 1],\n",
    "    'sentence': sentences,\n",
    "    'category': labels\n",
    "})\n",
    "\n",
    "# Interactive plot\n",
    "fig = px.scatter(\n",
    "    df, \n",
    "    x='x', \n",
    "    y='y',\n",
    "    color='category',\n",
    "    hover_data=['sentence'],\n",
    "    title='Sentence Embeddings - Hover for Details',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=12))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hover over points** to see the sentences. Notice how semantic clusters emerge naturally!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quick Clustering Preview\n",
    "\n",
    "Let's see if we can automatically discover these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run HDBSCAN clustering\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=3, metric='euclidean')\n",
    "cluster_labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "print(f\"Found {len(set(cluster_labels)) - 1} clusters (plus noise)\")\n",
    "print(f\"Cluster assignments: {cluster_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters\n",
    "df['cluster'] = cluster_labels\n",
    "\n",
    "fig = px.scatter(\n",
    "    df, \n",
    "    x='x', \n",
    "    y='y',\n",
    "    color='cluster',\n",
    "    hover_data=['sentence', 'category'],\n",
    "    title='Automatically Discovered Clusters',\n",
    "    width=800,\n",
    "    height=600,\n",
    "    color_continuous_scale='viridis'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=12))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The algorithm found meaningful clusters without being told the categories!**\n",
    "\n",
    "This is **concept emergence** ‚Äî exactly what we'll explore in Week 4.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Key Takeaways\n",
    "\n",
    "1. **Embeddings capture meaning**: Similar sentences ‚Üí similar vectors\n",
    "2. **Geometry encodes semantics**: Categories form clusters in embedding space\n",
    "3. **Concepts can emerge**: Clustering finds structure without labels\n",
    "\n",
    "This is the foundation of everything we'll build in Aegir!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Challenge (Optional)\n",
    "\n",
    "Try adding your own sentences! What clusters do they join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your sentences here\n",
    "my_sentences = [\n",
    "    \"Replace this with your own sentence!\",\n",
    "    # Add more...\n",
    "]\n",
    "\n",
    "# Embed and find nearest\n",
    "my_embeddings = model.encode(my_sentences)\n",
    "\n",
    "for sent, emb in zip(my_sentences, my_embeddings):\n",
    "    sims = cosine_similarity([emb], embeddings)[0]\n",
    "    best_idx = sims.argmax()\n",
    "    print(f\"\\n'{sent[:50]}...'\")\n",
    "    print(f\"  ‚Üí Most similar to: '{sentences[best_idx][:50]}...' ({labels[best_idx]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîó Next Up\n",
    "\n",
    "‚Üí [Week 1: Foundations](../../syllabus/week-01-foundations.md) - NumPy, PyTorch, linear algebra, calculus\n",
    "\n",
    "---\n",
    "\n",
    "## üêá Rabbit Holes (Optional)\n",
    "\n",
    "- [How do sentence transformers work?](../wiki/embeddings.md)\n",
    "- [What is UMAP actually doing?](https://arxiv.org/abs/1802.03426)\n",
    "- [Why cosine similarity?](https://en.wikipedia.org/wiki/Cosine_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
