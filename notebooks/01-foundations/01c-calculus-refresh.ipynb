{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01c: Calculus Refresh\n",
    "\n",
    "**Week 1, Day 5** | Foundations\n",
    "\n",
    "**Prerequisites**: 01a (tensors, autograd), 01b (vectors, matrices)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- [ ] Compute derivatives symbolically and numerically\n",
    "- [ ] Understand gradients as \"direction of steepest ascent\"\n",
    "- [ ] Apply the chain rule (the heart of backpropagation)\n",
    "- [ ] Implement gradient descent from scratch\n",
    "- [ ] **MILESTONE**: Optimize the Rosenbrock function\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "# Config\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Derivatives\n",
    "\n",
    "## Layer 1: Intuition — Rate of change\n",
    "\n",
    "A derivative answers: **\"If I nudge the input a little, how much does the output change?\"**\n",
    "\n",
    "**Physical analogies**:\n",
    "\n",
    "| Function | Derivative | Meaning |\n",
    "|----------|------------|---------|\n",
    "| Position | Velocity | How fast am I moving? |\n",
    "| Velocity | Acceleration | How fast is my speed changing? |\n",
    "| Cost | Marginal cost | How much more does one extra unit cost? |\n",
    "| Loss | Gradient | Which way should I adjust parameters? |\n",
    "\n",
    "**Visual intuition**: The derivative is the **slope of the tangent line**. A steep slope means small input changes cause big output changes.\n",
    "\n",
    "```\n",
    "      y │      ╱\n",
    "        │     ╱ ← tangent line (derivative)\n",
    "        │   .╱.\n",
    "        │  ╱.   .\n",
    "        │ ╱  . ← curve f(x)\n",
    "        │╱    .\n",
    "      ──┼─────────── x\n",
    "        │\n",
    "```\n",
    "\n",
    "**Why derivatives for ML?**: The loss function measures \"how wrong we are.\" Its derivative tells us which direction to adjust weights to be less wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 2: Code + Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical derivative: the finite difference approximation\n",
    "\n",
    "def numerical_derivative(f, x, h=1e-7):\n",
    "    \"\"\"\n",
    "    Compute derivative of f at x using central difference.\n",
    "    \n",
    "    The central difference formula:\n",
    "    f'(x) ≈ (f(x+h) - f(x-h)) / (2h)\n",
    "    \n",
    "    This is more accurate than the forward difference (f(x+h) - f(x)) / h.\n",
    "    \"\"\"\n",
    "    return (f(x + h) - f(x - h)) / (2 * h)\n",
    "\n",
    "# Test on f(x) = x²\n",
    "f = lambda x: x**2\n",
    "f_prime_exact = lambda x: 2*x  # We know this analytically\n",
    "\n",
    "test_points = [0, 1, 2, 3]\n",
    "print(\"f(x) = x²,  f'(x) = 2x\\n\")\n",
    "for x in test_points:\n",
    "    numerical = numerical_derivative(f, x)\n",
    "    exact = f_prime_exact(x)\n",
    "    print(f\"x = {x}: numerical f'({x}) = {numerical:.6f}, exact = {exact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize derivative as tangent line slope\n",
    "\n",
    "def plot_function_with_tangent(f, f_prime, x0, x_range=(-3, 3), title=\"\"):\n",
    "    \"\"\"\n",
    "    Plot function and its tangent line at x0.\n",
    "    \"\"\"\n",
    "    x = np.linspace(x_range[0], x_range[1], 200)\n",
    "    y = f(x)\n",
    "    \n",
    "    # Tangent line: y = f(x0) + f'(x0) * (x - x0)\n",
    "    slope = f_prime(x0)\n",
    "    tangent = f(x0) + slope * (x - x0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(x, y, 'b-', linewidth=2, label='f(x)')\n",
    "    ax.plot(x, tangent, 'r--', linewidth=2, label=f'Tangent at x={x0} (slope={slope:.2f})')\n",
    "    ax.scatter([x0], [f(x0)], color='red', s=100, zorder=5)\n",
    "    \n",
    "    ax.set_xlim(x_range)\n",
    "    ax.set_ylim(-2, 10)\n",
    "    ax.axhline(y=0, color='k', linewidth=0.5)\n",
    "    ax.axvline(x=0, color='k', linewidth=0.5)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title(title or f\"f(x) with tangent at x = {x0}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "# f(x) = x²\n",
    "f = lambda x: x**2\n",
    "f_prime = lambda x: 2*x\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, x0 in enumerate([-1, 0, 2]):\n",
    "    ax = axes[i]\n",
    "    x = np.linspace(-3, 3, 200)\n",
    "    ax.plot(x, f(x), 'b-', linewidth=2, label='f(x) = x²')\n",
    "    slope = f_prime(x0)\n",
    "    tangent = f(x0) + slope * (x - x0)\n",
    "    ax.plot(x, tangent, 'r--', linewidth=2, label=f\"Tangent (slope={slope})\")\n",
    "    ax.scatter([x0], [f(x0)], color='red', s=100, zorder=5)\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-2, 10)\n",
    "    ax.axhline(y=0, color='k', linewidth=0.5)\n",
    "    ax.axvline(x=0, color='k', linewidth=0.5)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.set_title(f\"x = {x0}, f'({x0}) = {slope}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common derivatives you should know\n",
    "\n",
    "functions = [\n",
    "    (\"x²\", lambda x: x**2, lambda x: 2*x, \"2x\"),\n",
    "    (\"x³\", lambda x: x**3, lambda x: 3*x**2, \"3x²\"),\n",
    "    (\"sin(x)\", np.sin, np.cos, \"cos(x)\"),\n",
    "    (\"cos(x)\", np.cos, lambda x: -np.sin(x), \"-sin(x)\"),\n",
    "    (\"eˣ\", np.exp, np.exp, \"eˣ\"),\n",
    "    (\"ln(x)\", np.log, lambda x: 1/x, \"1/x\"),\n",
    "]\n",
    "\n",
    "print(\"Common derivatives:\\n\")\n",
    "print(f\"{'f(x)':<12} {'f\\'(x)':<12} {'Numerical at x=2':<20} {'Exact at x=2':<15}\")\n",
    "print(\"-\" * 60)\n",
    "for name, f, f_prime, f_prime_name in functions:\n",
    "    x = 2.0\n",
    "    numerical = numerical_derivative(f, x)\n",
    "    exact = f_prime(x)\n",
    "    print(f\"{name:<12} {f_prime_name:<12} {numerical:<20.6f} {exact:<15.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 3: CS Speak\n",
    "\n",
    "### Derivative Computation Methods\n",
    "\n",
    "| Method | Formula | Error | Use case |\n",
    "|--------|---------|-------|----------|\n",
    "| **Symbolic** | Apply rules (power rule, chain rule) | Exact | Small expressions |\n",
    "| **Numerical** | $(f(x+h) - f(x-h))/(2h)$ | $O(h^2)$ | Black-box functions |\n",
    "| **Automatic (autograd)** | Track computation graph | Exact (to floating point) | Deep learning |\n",
    "\n",
    "### Numerical Stability\n",
    "\n",
    "Choosing $h$ in numerical differentiation is tricky:\n",
    "- Too large: truncation error (approximation is poor)\n",
    "- Too small: round-off error (floating point precision)\n",
    "\n",
    "Sweet spot: $h \\approx \\sqrt{\\epsilon_{machine}} \\approx 10^{-8}$ for float64.\n",
    "\n",
    "### Autograd Advantage\n",
    "\n",
    "Numerical differentiation scales as $O(n)$ for $n$ parameters (need $2n$ function evaluations).\n",
    "\n",
    "Autograd (reverse-mode) scales as $O(1)$ in the number of outputs — one backward pass gives ALL gradients. This is why we can train networks with millions of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 4: Mathematical Formalism\n",
    "\n",
    "### Definition\n",
    "\n",
    "The derivative of $f: \\mathbb{R} \\to \\mathbb{R}$ at $x$ is:\n",
    "\n",
    "$$f'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}$$\n",
    "\n",
    "if this limit exists.\n",
    "\n",
    "### Derivative Rules\n",
    "\n",
    "**Linearity**: $(af + bg)' = af' + bg'$\n",
    "\n",
    "**Product rule**: $(fg)' = f'g + fg'$\n",
    "\n",
    "**Quotient rule**: $(f/g)' = (f'g - fg')/g^2$\n",
    "\n",
    "**Chain rule**: $(f \\circ g)'(x) = f'(g(x)) \\cdot g'(x)$\n",
    "\n",
    "### Power Rule\n",
    "\n",
    "$$\\frac{d}{dx}x^n = nx^{n-1}$$\n",
    "\n",
    "for any real $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Gradients\n",
    "\n",
    "## Layer 1: Intuition — Which way is uphill?\n",
    "\n",
    "A derivative tells you the slope for a function of ONE variable. But what if your function depends on MULTIPLE variables?\n",
    "\n",
    "The **gradient** is the collection of all partial derivatives — it tells you the direction of steepest increase.\n",
    "\n",
    "**Physical analogy**: You're on a hilly terrain in fog. You can't see far, but you can feel the ground under your feet. The gradient tells you: \"The steepest uphill direction is THAT way.\"\n",
    "\n",
    "- **Gradient** points uphill (direction of steepest ascent)\n",
    "- **Negative gradient** points downhill (direction of steepest descent)\n",
    "- **Magnitude of gradient** tells you how steep the slope is\n",
    "\n",
    "To minimize a loss function, we walk in the direction of the **negative gradient**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 2: Code + Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial derivatives: derivative w.r.t. one variable, holding others fixed\n",
    "\n",
    "# f(x, y) = x² + y²\n",
    "def f(x, y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "# Partial derivatives\n",
    "def df_dx(x, y):\n",
    "    return 2*x  # ∂f/∂x: treat y as constant, differentiate w.r.t. x\n",
    "\n",
    "def df_dy(x, y):\n",
    "    return 2*y  # ∂f/∂y: treat x as constant, differentiate w.r.t. y\n",
    "\n",
    "# The gradient is [∂f/∂x, ∂f/∂y]\n",
    "def gradient(x, y):\n",
    "    return np.array([df_dx(x, y), df_dy(x, y)])\n",
    "\n",
    "# Test\n",
    "point = (3, 4)\n",
    "print(f\"f(x, y) = x² + y²\")\n",
    "print(f\"At point {point}:\")\n",
    "print(f\"  f{point} = {f(*point)}\")\n",
    "print(f\"  ∂f/∂x = {df_dx(*point)}\")\n",
    "print(f\"  ∂f/∂y = {df_dy(*point)}\")\n",
    "print(f\"  ∇f = {gradient(*point)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the gradient field on a surface\n",
    "\n",
    "def f(x, y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "def gradient(x, y):\n",
    "    return np.array([2*x, 2*y])\n",
    "\n",
    "# Create meshgrid\n",
    "x = np.linspace(-3, 3, 50)\n",
    "y = np.linspace(-3, 3, 50)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f(X, Y)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Left: 3D surface\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax.plot_surface(X, Y, Z, cmap=cm.viridis, alpha=0.8, edgecolor='none')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('f(x, y)')\n",
    "ax.set_title('f(x, y) = x² + y²\\n(a \"bowl\" with minimum at origin)')\n",
    "\n",
    "# Right: Contour plot with gradient arrows\n",
    "ax = axes[1]\n",
    "contour = ax.contourf(X, Y, Z, levels=20, cmap=cm.viridis, alpha=0.8)\n",
    "plt.colorbar(contour, ax=ax, label='f(x,y)')\n",
    "\n",
    "# Gradient arrows at selected points\n",
    "arrow_points = [(-2, -2), (-2, 2), (2, -2), (2, 2), (0, 2), (2, 0), (1, 1)]\n",
    "for px, py in arrow_points:\n",
    "    grad = gradient(px, py)\n",
    "    # Scale arrows for visibility\n",
    "    scale = 0.15\n",
    "    ax.quiver(px, py, grad[0]*scale, grad[1]*scale, \n",
    "              color='red', width=0.01, scale=1, scale_units='xy')\n",
    "\n",
    "ax.scatter(*zip(*arrow_points), c='red', s=30, zorder=5)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title('Gradient field (red arrows point uphill)\\n'\n",
    "             'To minimize: follow negative gradient (downhill)')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNotice: Gradients point away from the minimum (origin).\")\n",
    "print(\"To minimize, we walk OPPOSITE to the gradient.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More interesting function: f(x, y) = sin(x) + cos(y)\n",
    "\n",
    "def f(x, y):\n",
    "    return np.sin(x) + np.cos(y)\n",
    "\n",
    "def gradient(x, y):\n",
    "    return np.array([np.cos(x), -np.sin(y)])\n",
    "\n",
    "# Create meshgrid\n",
    "x = np.linspace(-np.pi, np.pi, 50)\n",
    "y = np.linspace(-np.pi, np.pi, 50)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f(X, Y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Contour plot\n",
    "contour = ax.contourf(X, Y, Z, levels=20, cmap=cm.coolwarm, alpha=0.8)\n",
    "plt.colorbar(contour, ax=ax, label='f(x,y)')\n",
    "\n",
    "# Gradient arrows on a coarser grid\n",
    "arrow_x = np.linspace(-np.pi, np.pi, 8)\n",
    "arrow_y = np.linspace(-np.pi, np.pi, 8)\n",
    "AX, AY = np.meshgrid(arrow_x, arrow_y)\n",
    "\n",
    "# Compute gradients\n",
    "GX = np.cos(AX)\n",
    "GY = -np.sin(AY)\n",
    "\n",
    "# Normalize for visibility\n",
    "magnitude = np.sqrt(GX**2 + GY**2)\n",
    "GX_norm = GX / (magnitude + 1e-10)\n",
    "GY_norm = GY / (magnitude + 1e-10)\n",
    "\n",
    "ax.quiver(AX, AY, GX_norm, GY_norm, color='black', alpha=0.7, scale=20)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title('f(x, y) = sin(x) + cos(y) with gradient field\\n'\n",
    "             'Arrows point toward increasing values')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 3: CS Speak\n",
    "\n",
    "### Gradient Computation\n",
    "\n",
    "```python\n",
    "# NumPy: manual\n",
    "def gradient(x, y):\n",
    "    return np.array([df_dx(x, y), df_dy(x, y)])\n",
    "\n",
    "# PyTorch: automatic\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = (x**2).sum()  # scalar output\n",
    "y.backward()\n",
    "print(x.grad)  # Gradient w.r.t. x\n",
    "```\n",
    "\n",
    "### Properties of Gradients\n",
    "\n",
    "- **Direction**: Points toward steepest ascent\n",
    "- **Magnitude**: $\\|\\nabla f\\|$ = rate of steepest ascent\n",
    "- **Perpendicular to level sets**: Gradients are orthogonal to contour lines\n",
    "\n",
    "### Directional Derivative\n",
    "\n",
    "The derivative in direction $\\mathbf{u}$ (unit vector):\n",
    "\n",
    "$$D_{\\mathbf{u}} f = \\nabla f \\cdot \\mathbf{u}$$\n",
    "\n",
    "Maximum when $\\mathbf{u}$ aligns with $\\nabla f$. This is why gradient points uphill!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 4: Mathematical Formalism\n",
    "\n",
    "### Definition\n",
    "\n",
    "For $f: \\mathbb{R}^n \\to \\mathbb{R}$, the **gradient** at $\\mathbf{x}$ is:\n",
    "\n",
    "$$\\nabla f(\\mathbf{x}) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n} \\end{bmatrix}$$\n",
    "\n",
    "### Partial Derivative\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x_i} = \\lim_{h \\to 0} \\frac{f(x_1, \\ldots, x_i + h, \\ldots, x_n) - f(x_1, \\ldots, x_i, \\ldots, x_n)}{h}$$\n",
    "\n",
    "### Gradient Properties\n",
    "\n",
    "**Linearity**: $\\nabla(af + bg) = a\\nabla f + b\\nabla g$\n",
    "\n",
    "**Product rule**: $\\nabla(fg) = f\\nabla g + g\\nabla f$\n",
    "\n",
    "**Chain rule**: For $h = f \\circ g$, $\\nabla h = (\\nabla f)(g) \\cdot J_g$\n",
    "\n",
    "where $J_g$ is the Jacobian matrix of $g$.\n",
    "\n",
    "### Directional Derivative Theorem\n",
    "\n",
    "For unit vector $\\mathbf{u}$:\n",
    "\n",
    "$$D_\\mathbf{u} f(\\mathbf{x}) = \\nabla f(\\mathbf{x}) \\cdot \\mathbf{u} \\leq \\|\\nabla f(\\mathbf{x})\\|$$\n",
    "\n",
    "with equality when $\\mathbf{u} = \\nabla f / \\|\\nabla f\\|$.\n",
    "\n",
    "**Proof**: By Cauchy-Schwarz. ∎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: The Chain Rule\n",
    "\n",
    "## Layer 1: Intuition — Rates multiply through compositions\n",
    "\n",
    "If function A doubles its input, and function B triples its input, then A(B(x)) multiplies by 6.\n",
    "\n",
    "More generally: if you change $x$ a little, how much does $f(g(x))$ change?\n",
    "\n",
    "1. First, $x$ changes $g(x)$ by rate $g'(x)$\n",
    "2. Then, that change in $g$ changes $f$ by rate $f'(g(x))$\n",
    "3. Total rate = multiply them: $f'(g(x)) \\cdot g'(x)$\n",
    "\n",
    "**Physical analogy**: Gears in a machine.\n",
    "- Gear A turns 2× for each turn of the input\n",
    "- Gear B turns 3× for each turn of A\n",
    "- Total: 6× from input to B\n",
    "\n",
    "**Why this is the heart of deep learning**: A neural network is a composition of many functions:\n",
    "\n",
    "$$\\text{output} = f_n(f_{n-1}(\\cdots f_1(\\text{input})))$$\n",
    "\n",
    "The chain rule lets us compute how each parameter affects the output by \"chaining\" through all the intermediate layers. This is **backpropagation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 2: Code + Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain rule example: f(g(x)) where f(u) = u², g(x) = sin(x)\n",
    "\n",
    "# Composition: h(x) = sin²(x)\n",
    "def h(x):\n",
    "    return np.sin(x)**2\n",
    "\n",
    "# Chain rule: h'(x) = f'(g(x)) · g'(x) = 2·sin(x) · cos(x) = sin(2x)\n",
    "def h_prime(x):\n",
    "    return 2 * np.sin(x) * np.cos(x)  # = sin(2x)\n",
    "\n",
    "# Verify numerically\n",
    "x_test = np.pi / 4\n",
    "numerical = numerical_derivative(h, x_test)\n",
    "exact = h_prime(x_test)\n",
    "\n",
    "print(f\"h(x) = sin²(x)\")\n",
    "print(f\"h'(x) = 2·sin(x)·cos(x) = sin(2x)\")\n",
    "print(f\"\\nAt x = π/4:\")\n",
    "print(f\"  Numerical h'(x) = {numerical:.6f}\")\n",
    "print(f\"  Exact h'(x)     = {exact:.6f}\")\n",
    "print(f\"  sin(2·π/4) = sin(π/2) = {np.sin(np.pi/2):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the chain rule as a computation graph\n",
    "\n",
    "# Simple example: y = (x + 2)²\n",
    "# Let's compute dy/dx step by step\n",
    "\n",
    "x = 3.0  # Input\n",
    "\n",
    "# Forward pass (compute the function)\n",
    "a = x + 2       # a = x + 2 = 5\n",
    "y = a**2        # y = a² = 25\n",
    "\n",
    "print(\"Forward pass:\")\n",
    "print(f\"  x = {x}\")\n",
    "print(f\"  a = x + 2 = {a}\")\n",
    "print(f\"  y = a² = {y}\")\n",
    "\n",
    "# Backward pass (compute gradients via chain rule)\n",
    "dy_dy = 1.0        # Gradient of y w.r.t. itself\n",
    "dy_da = 2 * a      # d(a²)/da = 2a\n",
    "da_dx = 1.0        # d(x+2)/dx = 1\n",
    "\n",
    "# Chain rule: dy/dx = dy/da · da/dx\n",
    "dy_dx = dy_da * da_dx\n",
    "\n",
    "print(\"\\nBackward pass (chain rule):\")\n",
    "print(f\"  dy/dy = {dy_dy}\")\n",
    "print(f\"  dy/da = 2a = 2·{a} = {dy_da}\")\n",
    "print(f\"  da/dx = 1\")\n",
    "print(f\"  dy/dx = dy/da · da/dx = {dy_da} · {da_dx} = {dy_dx}\")\n",
    "\n",
    "# Verify: d/dx[(x+2)²] = 2(x+2) = 2·5 = 10\n",
    "print(f\"\\nVerification: d/dx[(x+2)²] = 2(x+2) = {2*(x+2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more complex example: simple neural network forward/backward pass\n",
    "\n",
    "# Network: y = σ(w·x + b) where σ is sigmoid\n",
    "# We want dy/dw and dy/db\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    s = sigmoid(z)\n",
    "    return s * (1 - s)\n",
    "\n",
    "# Parameters\n",
    "x = 2.0    # Input\n",
    "w = 0.5    # Weight\n",
    "b = -1.0   # Bias\n",
    "\n",
    "# Forward pass\n",
    "z = w * x + b        # Linear combination\n",
    "y = sigmoid(z)       # Activation\n",
    "\n",
    "print(\"Forward pass:\")\n",
    "print(f\"  x = {x}, w = {w}, b = {b}\")\n",
    "print(f\"  z = w·x + b = {w}·{x} + {b} = {z}\")\n",
    "print(f\"  y = σ(z) = {y:.4f}\")\n",
    "\n",
    "# Backward pass\n",
    "dy_dz = sigmoid_derivative(z)  # σ'(z) = σ(z)(1-σ(z))\n",
    "dz_dw = x                       # ∂(wx+b)/∂w = x\n",
    "dz_db = 1                       # ∂(wx+b)/∂b = 1\n",
    "\n",
    "# Chain rule\n",
    "dy_dw = dy_dz * dz_dw\n",
    "dy_db = dy_dz * dz_db\n",
    "\n",
    "print(\"\\nBackward pass (chain rule):\")\n",
    "print(f\"  dy/dz = σ'(z) = σ(z)(1-σ(z)) = {dy_dz:.4f}\")\n",
    "print(f\"  dz/dw = x = {dz_dw}\")\n",
    "print(f\"  dz/db = 1\")\n",
    "print(f\"  dy/dw = dy/dz · dz/dw = {dy_dz:.4f} · {dz_dw} = {dy_dw:.4f}\")\n",
    "print(f\"  dy/db = dy/dz · dz/db = {dy_dz:.4f} · {dz_db} = {dy_db:.4f}\")\n",
    "\n",
    "# Verify with PyTorch\n",
    "print(\"\\nVerification with PyTorch autograd:\")\n",
    "w_t = torch.tensor(w, requires_grad=True)\n",
    "b_t = torch.tensor(b, requires_grad=True)\n",
    "x_t = torch.tensor(x)\n",
    "\n",
    "z_t = w_t * x_t + b_t\n",
    "y_t = torch.sigmoid(z_t)\n",
    "y_t.backward()\n",
    "\n",
    "print(f\"  dy/dw (PyTorch) = {w_t.grad.item():.4f}\")\n",
    "print(f\"  dy/db (PyTorch) = {b_t.grad.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 3: CS Speak\n",
    "\n",
    "### Backpropagation = Chain Rule + Dynamic Programming\n",
    "\n",
    "Backpropagation is efficient because it:\n",
    "1. Computes derivatives in reverse order (output → input)\n",
    "2. Reuses intermediate results (dynamic programming)\n",
    "\n",
    "**Complexity**:\n",
    "- Forward pass: $O(\\text{model size})$\n",
    "- Backward pass: $O(\\text{model size})$ — same order!\n",
    "\n",
    "Compare to numerical differentiation: $O(\\text{parameters} \\times \\text{model size})$\n",
    "\n",
    "### Computation Graph\n",
    "\n",
    "```\n",
    "Forward:  x → [×w] → [+b] → [σ] → y\n",
    "\n",
    "Backward: dy/dx ← dy/dz·dz/dx ← dy/da·da/dz ← dy/dy\n",
    "```\n",
    "\n",
    "Each node stores its local gradient. Backprop multiplies them together.\n",
    "\n",
    "### Common Local Gradients\n",
    "\n",
    "| Operation | Local gradient |\n",
    "|-----------|---------------|\n",
    "| $y = x + c$ | $\\partial y/\\partial x = 1$ |\n",
    "| $y = cx$ | $\\partial y/\\partial x = c$ |\n",
    "| $y = x^2$ | $\\partial y/\\partial x = 2x$ |\n",
    "| $y = e^x$ | $\\partial y/\\partial x = e^x$ |\n",
    "| $y = \\sigma(x)$ | $\\partial y/\\partial x = \\sigma(x)(1-\\sigma(x))$ |\n",
    "| $y = \\text{ReLU}(x)$ | $\\partial y/\\partial x = \\mathbf{1}_{x > 0}$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 4: Mathematical Formalism\n",
    "\n",
    "### Univariate Chain Rule\n",
    "\n",
    "For $h = f \\circ g$:\n",
    "\n",
    "$$\\frac{dh}{dx} = \\frac{df}{dg} \\cdot \\frac{dg}{dx} = f'(g(x)) \\cdot g'(x)$$\n",
    "\n",
    "### Multivariate Chain Rule\n",
    "\n",
    "For $f: \\mathbb{R}^m \\to \\mathbb{R}$ and $\\mathbf{g}: \\mathbb{R}^n \\to \\mathbb{R}^m$:\n",
    "\n",
    "$$\\frac{\\partial (f \\circ \\mathbf{g})}{\\partial x_i} = \\sum_{j=1}^{m} \\frac{\\partial f}{\\partial g_j} \\cdot \\frac{\\partial g_j}{\\partial x_i}$$\n",
    "\n",
    "In matrix form:\n",
    "\n",
    "$$\\nabla_\\mathbf{x}(f \\circ \\mathbf{g}) = \\mathbf{J}_\\mathbf{g}^T \\nabla_\\mathbf{g} f$$\n",
    "\n",
    "where $\\mathbf{J}_\\mathbf{g}$ is the Jacobian matrix $(\\partial g_j / \\partial x_i)$.\n",
    "\n",
    "### Vector-Jacobian Product (VJP)\n",
    "\n",
    "The key operation in backpropagation:\n",
    "\n",
    "$$\\mathbf{v}^T \\mathbf{J}$$\n",
    "\n",
    "where $\\mathbf{v}$ is the upstream gradient and $\\mathbf{J}$ is the local Jacobian.\n",
    "\n",
    "This can be computed without explicitly forming $\\mathbf{J}$ — crucial for efficiency!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Gradient Descent\n",
    "\n",
    "## Layer 1: Intuition — Following the downhill path\n",
    "\n",
    "Gradient descent is remarkably simple:\n",
    "\n",
    "1. **Look around**: Compute the gradient (which way is uphill?)\n",
    "2. **Walk downhill**: Take a step in the opposite direction\n",
    "3. **Repeat**: Keep walking until you reach a valley\n",
    "\n",
    "**Physical analogy**: A ball rolling down a bowl. It naturally finds the bottom.\n",
    "\n",
    "The **learning rate** (step size) is crucial:\n",
    "- Too small: Takes forever to converge\n",
    "- Too large: Overshoots and bounces around (or diverges!)\n",
    "- Just right: Smooth convergence\n",
    "\n",
    "**Why \"descent\" and not just random search?** The gradient tells us the BEST direction to move. Any other direction makes less progress per step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 2: Code + Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent from scratch\n",
    "\n",
    "def gradient_descent(f, grad_f, x0, lr=0.1, n_steps=100, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Minimize f starting from x0 using gradient descent.\n",
    "    \n",
    "    Args:\n",
    "        f: Function to minimize\n",
    "        grad_f: Gradient of f\n",
    "        x0: Starting point (numpy array)\n",
    "        lr: Learning rate (step size)\n",
    "        n_steps: Maximum iterations\n",
    "        tol: Convergence tolerance\n",
    "    \n",
    "    Returns:\n",
    "        x_opt: Optimized point\n",
    "        history: List of (x, f(x)) at each step\n",
    "    \"\"\"\n",
    "    x = x0.copy()\n",
    "    history = [(x.copy(), f(x))]\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        grad = grad_f(x)\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            print(f\"Converged at step {i} (gradient norm < {tol})\")\n",
    "            break\n",
    "        \n",
    "        # Update: x = x - lr * gradient\n",
    "        x = x - lr * grad\n",
    "        history.append((x.copy(), f(x)))\n",
    "    \n",
    "    return x, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Minimize f(x, y) = x² + y² (simple bowl)\n",
    "\n",
    "def f(xy):\n",
    "    return xy[0]**2 + xy[1]**2\n",
    "\n",
    "def grad_f(xy):\n",
    "    return np.array([2*xy[0], 2*xy[1]])\n",
    "\n",
    "# Run gradient descent\n",
    "x0 = np.array([4.0, 3.0])\n",
    "x_opt, history = gradient_descent(f, grad_f, x0, lr=0.2, n_steps=50)\n",
    "\n",
    "print(f\"Starting point: {x0}, f = {f(x0)}\")\n",
    "print(f\"Optimal point: {x_opt}, f = {f(x_opt):.6f}\")\n",
    "print(f\"True minimum: [0, 0], f = 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the optimization path\n",
    "\n",
    "# Create meshgrid for contour plot\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = np.linspace(-5, 5, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = X**2 + Y**2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Contour plot\n",
    "contour = ax.contour(X, Y, Z, levels=15, cmap='viridis')\n",
    "ax.clabel(contour, inline=True, fontsize=8)\n",
    "\n",
    "# Optimization path\n",
    "path = np.array([h[0] for h in history])\n",
    "ax.plot(path[:, 0], path[:, 1], 'ro-', markersize=4, linewidth=1, label='Gradient descent path')\n",
    "ax.scatter(path[0, 0], path[0, 1], c='green', s=100, zorder=5, label='Start')\n",
    "ax.scatter(path[-1, 0], path[-1, 1], c='red', s=100, zorder=5, label='End')\n",
    "ax.scatter(0, 0, c='blue', s=100, marker='*', zorder=5, label='True minimum')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title(f'Gradient Descent on f(x,y) = x² + y²\\nLearning rate = 0.2, {len(history)} steps')\n",
    "ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate matters! Comparison\n",
    "\n",
    "learning_rates = [0.01, 0.1, 0.5, 0.9]\n",
    "x0 = np.array([4.0, 3.0])\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for ax, lr in zip(axes.flat, learning_rates):\n",
    "    # Run gradient descent\n",
    "    x_opt, history = gradient_descent(f, grad_f, x0, lr=lr, n_steps=50)\n",
    "    \n",
    "    # Contour plot\n",
    "    contour = ax.contour(X, Y, Z, levels=15, cmap='viridis', alpha=0.5)\n",
    "    \n",
    "    # Path\n",
    "    path = np.array([h[0] for h in history])\n",
    "    ax.plot(path[:, 0], path[:, 1], 'ro-', markersize=3, linewidth=1)\n",
    "    ax.scatter(path[0, 0], path[0, 1], c='green', s=80, zorder=5)\n",
    "    ax.scatter(0, 0, c='blue', s=80, marker='*', zorder=5)\n",
    "    \n",
    "    # Loss curve\n",
    "    losses = [h[1] for h in history]\n",
    "    \n",
    "    ax.set_xlim(-6, 6)\n",
    "    ax.set_ylim(-6, 6)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'lr = {lr}\\nFinal f = {losses[-1]:.4f} ({len(history)} steps)')\n",
    "\n",
    "plt.suptitle('Effect of Learning Rate on Gradient Descent', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss curves comparison\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for lr in [0.01, 0.1, 0.3, 0.5]:\n",
    "    x_opt, history = gradient_descent(f, grad_f, x0, lr=lr, n_steps=100)\n",
    "    losses = [h[1] for h in history]\n",
    "    ax.semilogy(losses, label=f'lr = {lr}')\n",
    "\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Loss (log scale)')\n",
    "ax.set_title('Convergence Speed vs Learning Rate')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 3: CS Speak\n",
    "\n",
    "### Gradient Descent Algorithm\n",
    "\n",
    "```python\n",
    "def gradient_descent(params, lr, n_steps):\n",
    "    for _ in range(n_steps):\n",
    "        loss = compute_loss(params)\n",
    "        grad = compute_gradient(params)\n",
    "        params = params - lr * grad\n",
    "    return params\n",
    "```\n",
    "\n",
    "### Variants\n",
    "\n",
    "| Variant | Update rule | Key idea |\n",
    "|---------|-------------|----------|\n",
    "| **Vanilla GD** | $\\theta \\leftarrow \\theta - \\eta \\nabla L$ | Basic version |\n",
    "| **SGD** | Same, but on mini-batch | Stochastic, faster per step |\n",
    "| **Momentum** | $v \\leftarrow \\beta v + \\nabla L$; $\\theta \\leftarrow \\theta - \\eta v$ | Accumulate velocity |\n",
    "| **Adam** | Adaptive learning rates | Most popular in practice |\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "- **Learning rate ($\\eta$)**: Most important! Start with 0.001-0.01\n",
    "- **Batch size**: Larger = more stable gradients, but slower per epoch\n",
    "- **Momentum ($\\beta$)**: Usually 0.9\n",
    "\n",
    "### Convergence Conditions\n",
    "\n",
    "For convex functions with L-Lipschitz gradients, GD with $\\eta < 1/L$ converges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 4: Mathematical Formalism\n",
    "\n",
    "### Gradient Descent Update\n",
    "\n",
    "$$\\mathbf{x}_{t+1} = \\mathbf{x}_t - \\eta \\nabla f(\\mathbf{x}_t)$$\n",
    "\n",
    "where $\\eta > 0$ is the learning rate.\n",
    "\n",
    "### Why It Works (Descent Lemma)\n",
    "\n",
    "If $f$ has L-Lipschitz continuous gradient:\n",
    "\n",
    "$$f(\\mathbf{y}) \\leq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^T(\\mathbf{y} - \\mathbf{x}) + \\frac{L}{2}\\|\\mathbf{y} - \\mathbf{x}\\|^2$$\n",
    "\n",
    "Setting $\\mathbf{y} = \\mathbf{x} - \\eta \\nabla f(\\mathbf{x})$:\n",
    "\n",
    "$$f(\\mathbf{x}_{t+1}) \\leq f(\\mathbf{x}_t) - \\eta(1 - \\frac{L\\eta}{2})\\|\\nabla f(\\mathbf{x}_t)\\|^2$$\n",
    "\n",
    "For $\\eta < 2/L$, we have guaranteed descent: $f(\\mathbf{x}_{t+1}) < f(\\mathbf{x}_t)$.\n",
    "\n",
    "### Convergence Rate\n",
    "\n",
    "For $\\mu$-strongly convex, $L$-smooth functions with $\\eta = 1/L$:\n",
    "\n",
    "$$f(\\mathbf{x}_t) - f(\\mathbf{x}^*) \\leq \\left(1 - \\frac{\\mu}{L}\\right)^t (f(\\mathbf{x}_0) - f(\\mathbf{x}^*))$$\n",
    "\n",
    "This is **linear convergence** — error decreases by a constant factor each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Week 1 Milestone: Rosenbrock Function\n",
    "\n",
    "The **Rosenbrock function** is a classic optimization test:\n",
    "\n",
    "$$f(x, y) = (1 - x)^2 + 100(y - x^2)^2$$\n",
    "\n",
    "It has:\n",
    "- A global minimum at $(1, 1)$ where $f = 0$\n",
    "- A curved, narrow valley that's easy to find but hard to follow\n",
    "\n",
    "Your task: **Implement gradient descent and visualize the optimization path.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosenbrock function and gradient\n",
    "\n",
    "def rosenbrock(xy):\n",
    "    \"\"\"The Rosenbrock function.\"\"\"\n",
    "    x, y = xy\n",
    "    return (1 - x)**2 + 100 * (y - x**2)**2\n",
    "\n",
    "def rosenbrock_grad(xy):\n",
    "    \"\"\"Gradient of the Rosenbrock function.\"\"\"\n",
    "    x, y = xy\n",
    "    dx = -2 * (1 - x) - 400 * x * (y - x**2)\n",
    "    dy = 200 * (y - x**2)\n",
    "    return np.array([dx, dy])\n",
    "\n",
    "# Verify gradient with numerical differentiation\n",
    "test_point = np.array([0.5, 0.5])\n",
    "h = 1e-7\n",
    "numerical_grad = np.array([\n",
    "    (rosenbrock(test_point + np.array([h, 0])) - rosenbrock(test_point - np.array([h, 0]))) / (2*h),\n",
    "    (rosenbrock(test_point + np.array([0, h])) - rosenbrock(test_point - np.array([0, h]))) / (2*h)\n",
    "])\n",
    "analytic_grad = rosenbrock_grad(test_point)\n",
    "\n",
    "print(f\"At {test_point}:\")\n",
    "print(f\"  Numerical gradient: {numerical_grad}\")\n",
    "print(f\"  Analytic gradient:  {analytic_grad}\")\n",
    "print(f\"  Match: {np.allclose(numerical_grad, analytic_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run gradient descent on Rosenbrock\n",
    "\n",
    "x0 = np.array([-1.0, 1.0])\n",
    "lr = 0.001  # Small learning rate needed for this challenging function\n",
    "n_steps = 10000\n",
    "\n",
    "x_opt, history = gradient_descent(rosenbrock, rosenbrock_grad, x0, lr=lr, n_steps=n_steps)\n",
    "\n",
    "print(f\"Starting point: {x0}, f = {rosenbrock(x0):.4f}\")\n",
    "print(f\"Final point: {x_opt}, f = {rosenbrock(x_opt):.6f}\")\n",
    "print(f\"True minimum: [1, 1], f = 0\")\n",
    "print(f\"Distance to optimum: {np.linalg.norm(x_opt - np.array([1, 1])):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the optimization path on Rosenbrock\n",
    "\n",
    "# Create meshgrid\n",
    "x = np.linspace(-2, 2, 200)\n",
    "y = np.linspace(-1, 3, 200)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = (1 - X)**2 + 100 * (Y - X**2)**2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Contour plot (log scale for better visualization)\n",
    "levels = np.logspace(-1, 3, 20)\n",
    "contour = ax.contour(X, Y, Z, levels=levels, cmap='viridis')\n",
    "ax.clabel(contour, inline=True, fontsize=8, fmt='%.0f')\n",
    "\n",
    "# Optimization path\n",
    "path = np.array([h[0] for h in history])\n",
    "# Subsample for visibility\n",
    "step = max(1, len(path) // 200)\n",
    "path_sub = path[::step]\n",
    "\n",
    "ax.plot(path_sub[:, 0], path_sub[:, 1], 'r.-', markersize=2, linewidth=0.5, alpha=0.7,\n",
    "        label=f'GD path ({len(history)} steps)')\n",
    "ax.scatter(path[0, 0], path[0, 1], c='green', s=150, zorder=5, label='Start', edgecolor='white')\n",
    "ax.scatter(path[-1, 0], path[-1, 1], c='red', s=150, zorder=5, label='End', edgecolor='white')\n",
    "ax.scatter(1, 1, c='blue', s=200, marker='*', zorder=5, label='True minimum (1,1)', edgecolor='white')\n",
    "\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title(f'Gradient Descent on Rosenbrock Function\\n'\n",
    "             f'lr = {lr}, steps = {len(history)}, final f = {rosenbrock(x_opt):.4f}',\n",
    "             fontsize=14)\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss curve\n",
    "\n",
    "losses = [h[1] for h in history]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.semilogy(losses)\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Loss (log scale)')\n",
    "ax.set_title('Rosenbrock Optimization: Loss vs Iteration')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMILESTONE COMPLETE!\")\n",
    "print(f\"You implemented gradient descent from scratch and optimized the Rosenbrock function.\")\n",
    "print(f\"Final loss: {losses[-1]:.6f}\")\n",
    "print(f\"Final position: {x_opt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Gradient Visualization\n",
    "\n",
    "Plot $f(x, y) = \\sin(x) + \\cos(y)$ as a 3D surface. Then create a 2D contour plot with gradient arrows at several points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Gradient Visualization\n",
    "\n",
    "def exercise1_gradient_viz():\n",
    "    \"\"\"\n",
    "    Create a 3D surface plot and 2D contour plot with gradients\n",
    "    for f(x, y) = sin(x) + cos(y).\n",
    "    \"\"\"\n",
    "    # TODO: Define f(x, y)\n",
    "    # TODO: Define gradient (analytical: [cos(x), -sin(y)])\n",
    "    # TODO: Create meshgrid\n",
    "    # TODO: Plot 3D surface\n",
    "    # TODO: Plot 2D contours with gradient arrows\n",
    "    pass\n",
    "\n",
    "exercise1_gradient_viz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Learning Rate Experiment\n",
    "\n",
    "Run gradient descent on $f(x) = x^4 - 3x^3 + 2$ starting from $x_0 = 4$.\n",
    "\n",
    "Try learning rates: 0.001, 0.01, 0.05, 0.1\n",
    "\n",
    "Questions:\n",
    "1. What happens when the learning rate is too large?\n",
    "2. What's the optimal learning rate?\n",
    "3. Where are the local minima of this function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Learning Rate Experiment\n",
    "\n",
    "def exercise2_learning_rate():\n",
    "    \"\"\"\n",
    "    Experiment with learning rates on f(x) = x⁴ - 3x³ + 2.\n",
    "    \"\"\"\n",
    "    # TODO: Define f(x) and f'(x)\n",
    "    # f'(x) = 4x³ - 9x²\n",
    "    \n",
    "    # TODO: Run gradient descent with different learning rates\n",
    "    # TODO: Plot the results\n",
    "    # TODO: Answer the questions\n",
    "    pass\n",
    "\n",
    "exercise2_learning_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Manual Backprop\n",
    "\n",
    "For a simple 2-layer network:\n",
    "$$y = \\sigma(w_2 \\cdot \\sigma(w_1 \\cdot x + b_1) + b_2)$$\n",
    "\n",
    "Compute $\\partial y / \\partial w_1$ by hand using the chain rule. Then verify with PyTorch autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Manual Backprop\n",
    "\n",
    "def exercise3_manual_backprop():\n",
    "    \"\"\"\n",
    "    Compute gradient of 2-layer network by hand and verify with PyTorch.\n",
    "    \"\"\"\n",
    "    # Network: y = σ(w2 · σ(w1 · x + b1) + b2)\n",
    "    \n",
    "    # Parameters\n",
    "    x = 1.0\n",
    "    w1, b1 = 0.5, 0.1\n",
    "    w2, b2 = -0.3, 0.2\n",
    "    \n",
    "    # TODO: Forward pass (compute y)\n",
    "    # TODO: Backward pass (compute dy/dw1 using chain rule)\n",
    "    # Chain: y → σ → (w2·h + b2) → h → σ → (w1·x + b1)\n",
    "    \n",
    "    # TODO: Verify with PyTorch\n",
    "    pass\n",
    "\n",
    "exercise3_manual_backprop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Why This Matters\n",
    "\n",
    "Everything in deep learning is gradient descent:\n",
    "\n",
    "| Concept | How it uses gradients |\n",
    "|---------|----------------------|\n",
    "| **Training** | Minimize loss via gradient descent |\n",
    "| **Backpropagation** | Chain rule to compute gradients efficiently |\n",
    "| **Adam, SGD** | Variants of gradient descent |\n",
    "| **Learning rate schedulers** | Adapt $\\eta$ during training |\n",
    "| **Regularization** | Add gradient penalty terms |\n",
    "\n",
    "The Rosenbrock function you optimized is a toy problem, but it shares key challenges with real neural networks:\n",
    "- Narrow valleys (ill-conditioning)\n",
    "- Sensitivity to learning rate\n",
    "- Need for many iterations\n",
    "\n",
    "In Week 5-6, we'll see how dynamical systems and variational calculus generalize these ideas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "**Essential**:\n",
    "- [3Blue1Brown: Essence of Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) — Visual intuition\n",
    "- [3Blue1Brown: Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) — Backprop visualization\n",
    "\n",
    "**Deep Dives**:\n",
    "- [Matrix Calculus for Deep Learning](https://explained.ai/matrix-calculus/) — Detailed reference\n",
    "- [An Overview of Gradient Descent Optimization Algorithms](https://ruder.io/optimizing-gradient-descent/) — SGD variants\n",
    "\n",
    "**Wiki**:\n",
    "- [Glossary](../../wiki/glossary.md) — gradient, chain rule, learning rate, backpropagation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection Questions\n",
    "\n",
    "Before moving to Week 2:\n",
    "\n",
    "1. **Why is autograd more efficient than numerical differentiation?**\n",
    "   - Think about the number of function evaluations needed...\n",
    "\n",
    "2. **What happens if all eigenvalues of the Hessian (second derivative matrix) are positive?**\n",
    "   - Hint: This relates to convexity and local minima.\n",
    "\n",
    "3. **Why is gradient descent called \"greedy\"? What are its limitations?**\n",
    "   - Think about local vs global minima...\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 Complete!\n",
    "\n",
    "You now have the mathematical foundations for the rest of this curriculum:\n",
    "\n",
    "✅ **Tensor manipulation** (NumPy/PyTorch)  \n",
    "✅ **Linear algebra** (transformations, eigenthings, SVD)  \n",
    "✅ **Calculus** (gradients, chain rule, optimization)  \n",
    "\n",
    "**Key insight**: All of machine learning is optimization. We define a loss, compute gradients, and descend. The magic is in choosing what to optimize.\n",
    "\n",
    "---\n",
    "\n",
    "→ [Week 2: Embeddings](../../syllabus/week-02-embeddings.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
