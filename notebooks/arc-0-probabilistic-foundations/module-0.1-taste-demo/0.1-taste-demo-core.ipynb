{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 0.1: Taste Demo \u2014 Salience Scoring \u2014 Core\n",
    "\n",
    "**Arc 0: Probabilistic Foundations** | Module 1 of 8\n",
    "\n",
    "**Prerequisites**: None\n",
    "\n",
    "**Time**: ~60-90 minutes\n",
    "\n",
    "**Implementation target**: buildlog `SalienceScorer` \u2014 replaces substring matching for rule compliance evaluation\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- [ ] Explain why substring matching fails for evaluating agent rule compliance\n",
    "- [ ] Decompose rule compliance into linguistic, structural, and outcome signals\n",
    "- [ ] Implement a `SalienceScorer` with configurable, updatable weights\n",
    "- [ ] State the falsifiable claim for your scorer and test it against intuitive ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided Code - Do NOT Edit\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Callable\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# INTRO\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "*[Hero image placeholder \u2014 a detective inspecting code through a magnifying glass,\n",
    "but the magnifying glass shows a probability distribution instead of the code]*\n",
    "\n",
    "## The Setup\n",
    "\n",
    "You built a rule learning system. It uses a Thompson Sampling bandit to select\n",
    "which rules to surface to AI coding agents. The bandit needs a reward signal:\n",
    "did the agent follow the rule?\n",
    "\n",
    "The current answer: `if rule_text in agent_output`.\n",
    "\n",
    "That is, we check if the rule's exact text appears somewhere in the output.\n",
    "This is the engineering equivalent of checking if someone read a book by\n",
    "searching their essay for the book's title.\n",
    "\n",
    "It's wrong. Let's build something better.\n",
    "\n",
    "**By the end of this notebook**, you'll have a working `SalienceScorer` that\n",
    "evaluates rule compliance through three signals \u2014 linguistic, structural, and\n",
    "outcome \u2014 and can explain its scores in plain English.\n",
    "\n",
    "Let's go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# LAYER 0: THE PROBLEM\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "Here are two rules from a real buildlog CLAUDE.md:\n",
    "\n",
    "- *\"Always define interfaces before implementations\"*\n",
    "- *\"Always validate parsed dates are within valid ranges\"*\n",
    "\n",
    "And here's agent output from a coding session:\n",
    "\n",
    "```python\n",
    "class PaymentProcessor:\n",
    "    def process(self, amount: float) -> bool:\n",
    "        if amount <= 0:\n",
    "            raise ValueError(\"Amount must be positive\")\n",
    "        return self._charge(amount)\n",
    "```\n",
    "\n",
    "The `contains` check says: neither rule was followed (the text doesn't appear).\n",
    "\n",
    "A human reviewer says: the interface rule is irrelevant here (no interface needed\n",
    "for a standalone processor), and the date rule is irrelevant (no dates involved).\n",
    "The agent did fine.\n",
    "\n",
    "The `contains` check is giving the bandit *wrong reward signals*. The bandit is\n",
    "learning from noise. This is worse than useless \u2014 it's actively harmful.\n",
    "\n",
    "**Three failure modes of substring matching:**\n",
    "\n",
    "1. **False negatives**: Agent follows the rule's *intent* without quoting it verbatim\n",
    "2. **False positives**: Agent mentions the rule text without actually following it\n",
    "3. **Irrelevance blindness**: Can't distinguish \"rule violated\" from \"rule doesn't apply\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# LAYER 1: INTUITION\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "Think about how a human code reviewer evaluates compliance. They check three things:\n",
    "\n",
    "1. **Does the output speak the rule's language?** (Linguistic signal)\n",
    "   - If the rule says \"define interfaces before implementations\" and the code has\n",
    "     `Protocol`, `ABC`, `abstractmethod` \u2014 that's a vocabulary match.\n",
    "\n",
    "2. **Does the output follow the rule's prescribed pattern?** (Structural signal)\n",
    "   - Is there an abstract class defined *before* the concrete class?\n",
    "\n",
    "3. **Did the task succeed?** (Outcome signal)\n",
    "   - A rule can't be \"followed\" if the thing it was supposed to help with broke.\n",
    "\n",
    "Our scorer combines these three signals with weights:\n",
    "\n",
    "```\n",
    "S = w_l * linguistic + w_s * structural + w_o * outcome\n",
    "```\n",
    "\n",
    "This is a weighted linear combination. It's the simplest model that could work.\n",
    "It's definitely wrong in interesting ways (we'll fix that later).\n",
    "But it's already dramatically better than `contains`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# LAYER 2: CODE + VIZ\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Problem 1: Set Up Mock Buildlog Entries and Show How `contains` Fails\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "Let's create realistic mock data. Each entry has a rule, agent output, task\n",
    "outcome, and your intuitive compliance rating (0-1) as ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BuildlogEntry:\n",
    "    \"\"\"A single buildlog entry with a rule, agent output, and ground truth.\"\"\"\n",
    "    rule: str\n",
    "    task: str\n",
    "    agent_output: str\n",
    "    task_succeeded: bool\n",
    "    intuitive_compliance: float  # Your expert rating, 0-1\n",
    "\n",
    "\n",
    "ENTRIES = [\n",
    "    # Entry 0: Perfect compliance -- interface defined before implementation\n",
    "    BuildlogEntry(\n",
    "        rule=\"Always define interfaces before implementations\",\n",
    "        task=\"Create a storage backend for user profiles\",\n",
    "        agent_output=\"\"\"I'll start with the interface:\n",
    "```python\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class StorageBackend(ABC):\n",
    "    @abstractmethod\n",
    "    def save(self, key: str, data: dict) -> None: ...\n",
    "    @abstractmethod\n",
    "    def load(self, key: str) -> dict: ...\n",
    "\n",
    "class PostgresBackend(StorageBackend):\n",
    "    def save(self, key, data):\n",
    "        self.conn.execute(\"INSERT INTO profiles ...\", data)\n",
    "    def load(self, key):\n",
    "        return self.conn.execute(\"SELECT ...\", key).fetchone()\n",
    "```\"\"\",\n",
    "        task_succeeded=True,\n",
    "        intuitive_compliance=0.95,\n",
    "    ),\n",
    "    # Entry 1: Rule doesn't apply -- no interface needed\n",
    "    BuildlogEntry(\n",
    "        rule=\"Always define interfaces before implementations\",\n",
    "        task=\"Write a utility function to slugify strings\",\n",
    "        agent_output=\"\"\"```python\n",
    "import re\n",
    "\n",
    "def slugify(text: str) -> str:\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'[^\\\\w\\\\s-]', '', text)\n",
    "    return re.sub(r'[-\\\\s]+', '-', text)\n",
    "```\n",
    "Simple utility -- no interface needed here.\"\"\",\n",
    "        task_succeeded=True,\n",
    "        intuitive_compliance=0.5,\n",
    "    ),\n",
    "    # Entry 2: Rule violated -- no interface, but one was needed\n",
    "    BuildlogEntry(\n",
    "        rule=\"Always define interfaces before implementations\",\n",
    "        task=\"Create a payment processor with multiple gateways\",\n",
    "        agent_output=\"\"\"```python\n",
    "class StripeProcessor:\n",
    "    def charge(self, amount): ...\n",
    "\n",
    "class PayPalProcessor:\n",
    "    def charge(self, amount): ...\n",
    "```\n",
    "Both processors handle charges directly.\"\"\",\n",
    "        task_succeeded=True,\n",
    "        intuitive_compliance=0.15,\n",
    "    ),\n",
    "    # Entry 3: Perfect date validation\n",
    "    BuildlogEntry(\n",
    "        rule=\"Always validate parsed dates are within valid ranges\",\n",
    "        task=\"Parse user-submitted event dates\",\n",
    "        agent_output=\"\"\"```python\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_event_date(raw: str) -> datetime:\n",
    "    dt = datetime.fromisoformat(raw)\n",
    "    if dt.year < 2020 or dt.year > 2030:\n",
    "        raise ValueError(f\"Date {dt} outside valid range 2020-2030\")\n",
    "    return dt\n",
    "```\"\"\",\n",
    "        task_succeeded=True,\n",
    "        intuitive_compliance=0.90,\n",
    "    ),\n",
    "    # Entry 4: Date parsing without validation\n",
    "    BuildlogEntry(\n",
    "        rule=\"Always validate parsed dates are within valid ranges\",\n",
    "        task=\"Import CSV with timestamps\",\n",
    "        agent_output=\"\"\"```python\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "def import_csv(path):\n",
    "    with open(path) as f:\n",
    "        for row in csv.reader(f):\n",
    "            ts = datetime.fromisoformat(row[3])\n",
    "            yield {\"name\": row[0], \"timestamp\": ts}\n",
    "```\"\"\",\n",
    "        task_succeeded=True,\n",
    "        intuitive_compliance=0.20,\n",
    "    ),\n",
    "    # Entry 5: No dates involved at all\n",
    "    BuildlogEntry(\n",
    "        rule=\"Always validate parsed dates are within valid ranges\",\n",
    "        task=\"Implement retry logic for HTTP requests\",\n",
    "        agent_output=\"\"\"```python\n",
    "import time\n",
    "import httpx\n",
    "\n",
    "def retry(url, max_retries=3):\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            return httpx.get(url)\n",
    "        except httpx.TimeoutException:\n",
    "            time.sleep(2 ** i)\n",
    "    raise RuntimeError(f\"Failed after {max_retries} retries\")\n",
    "```\"\"\",\n",
    "        task_succeeded=True,\n",
    "        intuitive_compliance=0.5,\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(ENTRIES)} mock buildlog entries.\")\n",
    "print(f\"Rules: {set(e.rule for e in ENTRIES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how `contains` does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_check(rule: str, output: str) -> float:\n",
    "    \"\"\"The current approach: does the rule text appear in the output?\"\"\"\n",
    "    return 1.0 if rule.lower() in output.lower() else 0.0\n",
    "\n",
    "\n",
    "print(\"Contains check results vs intuitive ratings:\\n\")\n",
    "print(f\"{'Entry':>7}  {'Contains':>9}  {'Intuitive':>10}  {'Delta':>6}  Rule\")\n",
    "print(\"  \" + \"-\" * 70)\n",
    "for i, e in enumerate(ENTRIES):\n",
    "    c = contains_check(e.rule, e.agent_output)\n",
    "    delta = abs(c - e.intuitive_compliance)\n",
    "    marker = \" <<<\" if delta > 0.4 else \"\"\n",
    "    print(f\"  Entry {i}:  {c:>8.2f}  {e.intuitive_compliance:>10.2f}  {delta:>5.2f}{marker}\")\n",
    "\n",
    "print(\"\\n<<< = error > 0.4 (bandit is learning wrong from these)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every entry gets 0.0 from `contains` \u2014 the rule text never appears verbatim.\n",
    "The bandit thinks *no rule was ever followed*. That's wrong for entries 0 and 3,\n",
    "and misleading for 1 and 5 (where the rule doesn't apply).\n",
    "\n",
    "Let's fix this one signal at a time.\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Problem 2: Linguistic Signal Detection\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "The linguistic signal asks: does the output use vocabulary associated with the rule?\n",
    "\n",
    "Your task:\n",
    "1. Implement `linguistic_signal(rule, output)` returning float in [0, 1]\n",
    "2. Extract keywords from the rule (words > 3 chars)\n",
    "3. Check for each keyword (or synonyms) in the output\n",
    "4. Weight code occurrences at 1.0, prose at 0.5\n",
    "\n",
    "Hint: separate code blocks from prose first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided Code - Do NOT Edit\n",
    "SYNONYM_MAP = {\n",
    "    \"interface\": [\"interface\", \"protocol\", \"abc\", \"abstract\"],\n",
    "    \"interfaces\": [\"interface\", \"protocol\", \"abc\", \"abstract\"],\n",
    "    \"implementations\": [\"implementation\", \"concrete\", \"class\"],\n",
    "    \"define\": [\"define\", \"create\", \"class\"],\n",
    "    \"validate\": [\"validate\", \"check\", \"verify\", \"assert\", \"raise\"],\n",
    "    \"parsed\": [\"parsed\", \"parse\", \"fromisoformat\", \"strptime\"],\n",
    "    \"dates\": [\"date\", \"datetime\", \"timestamp\"],\n",
    "    \"valid\": [\"valid\", \"range\", \"between\", \"boundary\"],\n",
    "    \"ranges\": [\"range\", \"between\", \"min\", \"max\", \"limit\"],\n",
    "    \"always\": [\"always\"],\n",
    "    \"within\": [\"within\", \"inside\", \"between\"],\n",
    "    \"before\": [\"before\", \"first\", \"prior\"],\n",
    "}\n",
    "\n",
    "\n",
    "def extract_code_blocks(text: str) -> tuple[str, str]:\n",
    "    \"\"\"Split text into (code, prose) by extracting ```...``` blocks.\"\"\"\n",
    "    code_blocks = re.findall(r'```(?:python)?\\n(.*?)```', text, re.DOTALL)\n",
    "    code = '\\n'.join(code_blocks)\n",
    "    prose = re.sub(r'```(?:python)?\\n.*?```', '', text, flags=re.DOTALL)\n",
    "    return code, prose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linguistic_signal(rule: str, output: str) -> float:\n",
    "    \"\"\"\n",
    "    Measure how much of the rule's key vocabulary appears in the output.\n",
    "    Code mentions weighted 1.0, prose mentions weighted 0.5.\n",
    "    Returns float in [0, 1].\n",
    "    \"\"\"\n",
    "    # --- YOUR CODE BELOW ---\n",
    "    pass\n",
    "\n",
    "\n",
    "# >>> SOLUTION (collapsed by default)\n",
    "# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# \u2502 def linguistic_signal(rule: str, output: str) -> float:\n",
    "# \u2502     keywords = [w.lower() for w in rule.split() if len(w) > 3]\n",
    "# \u2502     if not keywords:\n",
    "# \u2502         return 0.0\n",
    "# \u2502     code, prose = extract_code_blocks(output)\n",
    "# \u2502     code_lower, prose_lower = code.lower(), prose.lower()\n",
    "# \u2502     scores = []\n",
    "# \u2502     for kw in keywords:\n",
    "# \u2502         synonyms = SYNONYM_MAP.get(kw, [kw])\n",
    "# \u2502         in_code = any(s in code_lower for s in synonyms)\n",
    "# \u2502         in_prose = any(s in prose_lower for s in synonyms)\n",
    "# \u2502         if in_code:\n",
    "# \u2502             scores.append(1.0)\n",
    "# \u2502         elif in_prose:\n",
    "# \u2502             scores.append(0.5)\n",
    "# \u2502         else:\n",
    "# \u2502             scores.append(0.0)\n",
    "# \u2502     return min(1.0, sum(scores) / len(scores))\n",
    "# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "\n",
    "\n",
    "# Test\n",
    "print(\"Linguistic signal scores:\")\n",
    "for i, e in enumerate(ENTRIES):\n",
    "    score = linguistic_signal(e.rule, e.agent_output)\n",
    "    print(f\"  Entry {i}: {score:.2f}  (intuitive: {e.intuitive_compliance:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Problem 3: Structural Signal Detection\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "The structural signal asks: does the output's *structure* match the rule's\n",
    "prescribed pattern? This is rule-specific.\n",
    "\n",
    "Your task:\n",
    "1. Implement `check_interface_before_impl(output)` \u2014 score in [0, 1]\n",
    "2. Implement `check_date_validation(output)` \u2014 score in [0, 1]\n",
    "3. Wire them up via `structural_signal(rule, output)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_interface_before_impl(output: str) -> float:\n",
    "    \"\"\"\n",
    "    1.0 = clear interface-first pattern\n",
    "    0.5 = interface exists but order unclear\n",
    "    0.25 = no interface but agent acknowledged rule doesn't apply\n",
    "    0.0 = no interface pattern detected\n",
    "    \"\"\"\n",
    "    # --- YOUR CODE BELOW ---\n",
    "    pass\n",
    "\n",
    "\n",
    "def check_date_validation(output: str) -> float:\n",
    "    \"\"\"\n",
    "    1.0 = date parsing with explicit range validation\n",
    "    0.5 = some validation but incomplete\n",
    "    0.25 = dates present but no validation\n",
    "    0.0 = no date handling detected\n",
    "    \"\"\"\n",
    "    # --- YOUR CODE BELOW ---\n",
    "    pass\n",
    "\n",
    "\n",
    "# >>> SOLUTION (collapsed by default)\n",
    "# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# \u2502 def check_interface_before_impl(output: str) -> float:\n",
    "# \u2502     code, prose = extract_code_blocks(output)\n",
    "# \u2502     has_abstract = bool(re.search(\n",
    "# \u2502         r'(class\\s+\\w+\\(\\s*(ABC|Protocol)\\s*\\)|@abstractmethod)', code\n",
    "# \u2502     ))\n",
    "# \u2502     has_concrete = bool(re.search(r'class\\s+\\w+', code))\n",
    "# \u2502     if has_abstract and has_concrete:\n",
    "# \u2502         abstract_pos = re.search(\n",
    "# \u2502             r'(class\\s+\\w+\\(\\s*(ABC|Protocol)\\s*\\)|Protocol)', code\n",
    "# \u2502         ).start()\n",
    "# \u2502         for m in re.finditer(r'class\\s+\\w+', code):\n",
    "# \u2502             if m.start() != abstract_pos and m.start() > abstract_pos:\n",
    "# \u2502                 return 1.0\n",
    "# \u2502         return 0.5\n",
    "# \u2502     acknowledged = bool(re.search(\n",
    "# \u2502         r'(no.*interface.*needed|utility|simple)', prose, re.I\n",
    "# \u2502     ))\n",
    "# \u2502     if acknowledged:\n",
    "# \u2502         return 0.25\n",
    "# \u2502     return 0.0\n",
    "# \u2502\n",
    "# \u2502 def check_date_validation(output: str) -> float:\n",
    "# \u2502     code, _ = extract_code_blocks(output)\n",
    "# \u2502     has_date = bool(re.search(r'(datetime|fromisoformat|strptime)', code, re.I))\n",
    "# \u2502     has_range = bool(re.search(\n",
    "# \u2502         r'(if.*(<|>|<=|>=).*\\d|raise.*ValueError)', code, re.I\n",
    "# \u2502     ))\n",
    "# \u2502     if has_date and has_range:\n",
    "# \u2502         return 1.0\n",
    "# \u2502     if has_date:\n",
    "# \u2502         return 0.25\n",
    "# \u2502     return 0.0\n",
    "# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "\n",
    "\n",
    "STRUCTURAL_PATTERNS = {\n",
    "    \"Always define interfaces before implementations\": check_interface_before_impl,\n",
    "    \"Always validate parsed dates are within valid ranges\": check_date_validation,\n",
    "}\n",
    "\n",
    "\n",
    "def structural_signal(rule: str, output: str) -> float:\n",
    "    \"\"\"Dispatch to the appropriate structural checker.\"\"\"\n",
    "    checker = STRUCTURAL_PATTERNS.get(rule)\n",
    "    return checker(output) if checker else 0.5\n",
    "\n",
    "\n",
    "# Test\n",
    "print(\"Structural signal scores:\")\n",
    "for i, e in enumerate(ENTRIES):\n",
    "    score = structural_signal(e.rule, e.agent_output)\n",
    "    print(f\"  Entry {i}: {score:.2f}  (intuitive: {e.intuitive_compliance:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Problem 4: Outcome Signal\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "The simplest signal: did the task succeed? Binary for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_signal(entry: BuildlogEntry) -> float:\n",
    "    \"\"\"1.0 if task succeeded, 0.0 otherwise.\"\"\"\n",
    "    # --- YOUR CODE BELOW ---\n",
    "    pass\n",
    "\n",
    "\n",
    "# >>> SOLUTION (collapsed by default)\n",
    "# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# \u2502 def outcome_signal(entry: BuildlogEntry) -> float:\n",
    "# \u2502     return 1.0 if entry.task_succeeded else 0.0\n",
    "# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "\n",
    "# Tests pass. Moving on.\n",
    "print(\"All entries succeeded (outcome = 1.0 for all).\")\n",
    "print(\"In real data, this differentiates. For now, linguistic + structural do the work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Problem 5: Assemble the SalienceScorer\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "Combine all three signals into a single class.\n",
    "\n",
    "Your task:\n",
    "1. Implement `SalienceScorer` with configurable weights\n",
    "2. Weights must be updatable (constitutional rule: not hardcoded forever)\n",
    "3. `score` returns a `SalienceResult` with component breakdown\n",
    "4. `explain` returns plain English (constitutional rule: explain 0.7)\n",
    "5. State the **falsifiable claim**: what would make this scorer wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SalienceResult:\n",
    "    \"\"\"Result with component breakdown.\"\"\"\n",
    "    score: float\n",
    "    linguistic: float\n",
    "    structural: float\n",
    "    outcome: float\n",
    "    weights: dict\n",
    "\n",
    "    def explain(self) -> str:\n",
    "        \"\"\"Plain-English explanation.\"\"\"\n",
    "        # --- YOUR CODE BELOW ---\n",
    "        pass\n",
    "\n",
    "\n",
    "class SalienceScorer:\n",
    "    \"\"\"\n",
    "    Scores agent output for rule compliance using three signals.\n",
    "\n",
    "    Falsifiable claim: Rankings agree with expert intuitive ratings\n",
    "    (Spearman rho > 0.8). If not, recalibrate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w_linguistic=0.4, w_structural=0.4, w_outcome=0.2):\n",
    "        # --- YOUR CODE BELOW ---\n",
    "        pass\n",
    "\n",
    "    def update_weights(self, w_l: float, w_s: float, w_o: float) -> None:\n",
    "        \"\"\"Update weights. Must sum to 1.\"\"\"\n",
    "        # --- YOUR CODE BELOW ---\n",
    "        pass\n",
    "\n",
    "    def score(self, entry: BuildlogEntry) -> SalienceResult:\n",
    "        \"\"\"Score a single buildlog entry.\"\"\"\n",
    "        # --- YOUR CODE BELOW ---\n",
    "        pass\n",
    "\n",
    "\n",
    "# >>> SOLUTION (collapsed by default)\n",
    "# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# \u2502 @dataclass\n",
    "# \u2502 class SalienceResult:\n",
    "# \u2502     score: float\n",
    "# \u2502     linguistic: float\n",
    "# \u2502     structural: float\n",
    "# \u2502     outcome: float\n",
    "# \u2502     weights: dict\n",
    "# \u2502\n",
    "# \u2502     def explain(self) -> str:\n",
    "# \u2502         level = (\n",
    "# \u2502             \"strong\" if self.score >= 0.75\n",
    "# \u2502             else \"moderate\" if self.score >= 0.5\n",
    "# \u2502             else \"weak\" if self.score >= 0.25\n",
    "# \u2502             else \"minimal\"\n",
    "# \u2502         )\n",
    "# \u2502         parts = []\n",
    "# \u2502         if self.linguistic >= 0.7:\n",
    "# \u2502             parts.append(\"uses relevant vocabulary\")\n",
    "# \u2502         elif self.linguistic >= 0.4:\n",
    "# \u2502             parts.append(\"some vocabulary overlap\")\n",
    "# \u2502         else:\n",
    "# \u2502             parts.append(\"little vocabulary match\")\n",
    "# \u2502         if self.structural >= 0.7:\n",
    "# \u2502             parts.append(\"follows the prescribed pattern\")\n",
    "# \u2502         elif self.structural >= 0.4:\n",
    "# \u2502             parts.append(\"partially follows the pattern\")\n",
    "# \u2502         else:\n",
    "# \u2502             parts.append(\"doesn't follow the pattern\")\n",
    "# \u2502         parts.append(\"task succeeded\" if self.outcome >= 0.5 else \"task failed\")\n",
    "# \u2502         return f\"Score {self.score:.2f} -- {level} compliance. The output {', '.join(parts)}.\"\n",
    "# \u2502\n",
    "# \u2502 class SalienceScorer:\n",
    "# \u2502     FALSIFIABLE_CLAIM = \"Rankings agree with expert ratings (Spearman rho > 0.8).\"\n",
    "# \u2502\n",
    "# \u2502     def __init__(self, w_linguistic=0.4, w_structural=0.4, w_outcome=0.2):\n",
    "# \u2502         self.update_weights(w_linguistic, w_structural, w_outcome)\n",
    "# \u2502\n",
    "# \u2502     def update_weights(self, w_l, w_s, w_o):\n",
    "# \u2502         total = w_l + w_s + w_o\n",
    "# \u2502         assert abs(total - 1.0) < 1e-6, f\"Weights must sum to 1, got {total}\"\n",
    "# \u2502         self.weights = {\"linguistic\": w_l, \"structural\": w_s, \"outcome\": w_o}\n",
    "# \u2502\n",
    "# \u2502     def score(self, entry):\n",
    "# \u2502         l = linguistic_signal(entry.rule, entry.agent_output)\n",
    "# \u2502         s = structural_signal(entry.rule, entry.agent_output)\n",
    "# \u2502         o = outcome_signal(entry)\n",
    "# \u2502         combined = self.weights[\"linguistic\"]*l + self.weights[\"structural\"]*s + self.weights[\"outcome\"]*o\n",
    "# \u2502         return SalienceResult(round(combined, 4), round(l, 4), round(s, 4), round(o, 4), dict(self.weights))\n",
    "# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Problem 6: Run the Scorer, Visualize, Test the Falsifiable Claim\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "Your task:\n",
    "1. Score all entries with default weights\n",
    "2. Create a side-by-side bar chart: salience score vs. intuitive rating\n",
    "3. Compute Spearman rank correlation -- does it beat 0.8?\n",
    "4. Print the explanation for each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats as scipy_stats\n",
    "\n",
    "scorer = SalienceScorer(w_linguistic=0.4, w_structural=0.4, w_outcome=0.2)\n",
    "\n",
    "# --- YOUR CODE BELOW ---\n",
    "# Score all entries, plot comparison, compute Spearman correlation\n",
    "\n",
    "\n",
    "# >>> SOLUTION (collapsed by default)\n",
    "# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# \u2502 results = [scorer.score(e) for e in ENTRIES]\n",
    "# \u2502 salience_scores = [r.score for r in results]\n",
    "# \u2502 intuitive = [e.intuitive_compliance for e in ENTRIES]\n",
    "# \u2502\n",
    "# \u2502 rho, pval = scipy_stats.spearmanr(salience_scores, intuitive)\n",
    "# \u2502 print(f\"Spearman rho: {rho:.3f}  (p={pval:.4f})\")\n",
    "# \u2502 print(f\"Falsifiable claim threshold: rho > 0.8\")\n",
    "# \u2502 print(f\"Result: {'PASS' if rho > 0.8 else 'NEEDS RECALIBRATION'}\")\n",
    "# \u2502 print()\n",
    "# \u2502\n",
    "# \u2502 x = np.arange(len(ENTRIES))\n",
    "# \u2502 width = 0.35\n",
    "# \u2502 fig, ax = plt.subplots(figsize=(12, 5))\n",
    "# \u2502 ax.bar(x - width/2, salience_scores, width, label='Salience Score', color='#2196F3')\n",
    "# \u2502 ax.bar(x + width/2, intuitive, width, label='Intuitive Rating', color='#FF9800')\n",
    "# \u2502 ax.set_xlabel('Entry')\n",
    "# \u2502 ax.set_ylabel('Score')\n",
    "# \u2502 ax.set_title('SalienceScorer vs. Intuitive Ratings')\n",
    "# \u2502 ax.set_xticks(x)\n",
    "# \u2502 ax.legend()\n",
    "# \u2502 ax.set_ylim(0, 1.1)\n",
    "# \u2502 plt.tight_layout()\n",
    "# \u2502 plt.show()\n",
    "# \u2502\n",
    "# \u2502 print(\"\\nExplanations:\")\n",
    "# \u2502 for i, (e, r) in enumerate(zip(ENTRIES, results)):\n",
    "# \u2502     print(f\"\\n  Entry {i}: {e.task[:50]}\")\n",
    "# \u2502     print(f\"    {r.explain()}\")\n",
    "# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory Backfill: Why a Weighted Linear Combination?\n",
    "\n",
    "We made two assumptions that are both wrong and both useful:\n",
    "\n",
    "1. **Linearity**: Signals combine additively. In reality, high structural + high\n",
    "   linguistic is stronger evidence than either alone (interaction effects).\n",
    "   But linear is the simplest baseline.\n",
    "\n",
    "2. **Independence**: The three signals are independent. They're not -- vocabulary\n",
    "   overlap correlates with structural compliance. But treating them as independent\n",
    "   lets us build and test each detector separately.\n",
    "\n",
    "Both assumptions break down. That's fine. Module 0.2 builds the probability\n",
    "foundations to handle more sophisticated models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# EXERCISES\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "## Exercise 1: Implement the SalienceScorer\n",
    "\n",
    "If you used the solutions above, go back and implement them yourself. Verify:\n",
    "- [ ] Weights are stored and updatable via `update_weights`\n",
    "- [ ] `update_weights` validates weights sum to 1\n",
    "- [ ] `score` returns a `SalienceResult` with all components\n",
    "- [ ] `explain` produces a readable sentence for any score\n",
    "\n",
    "## Exercise 2: Compare and Tune\n",
    "\n",
    "Try different weight configurations:\n",
    "- `(0.7, 0.2, 0.1)` \u2014 linguistic-heavy\n",
    "- `(0.2, 0.7, 0.1)` \u2014 structural-heavy\n",
    "- `(0.33, 0.33, 0.34)` \u2014 uniform\n",
    "\n",
    "Which gives the highest Spearman correlation? Why?\n",
    "\n",
    "## Exercise 3 [PUBLISH]: Write the \"Contains Check Takedown\"\n",
    "\n",
    "Write 500-800 words explaining why substring matching fails for evaluating\n",
    "agent rule compliance. Target: practitioners building AI agent systems.\n",
    "\n",
    "Structure:\n",
    "1. The problem: you have rules, you need to evaluate compliance\n",
    "2. The naive approach: `contains` / substring matching\n",
    "3. Three failure modes (use examples from this notebook)\n",
    "4. The alternative: decompose into linguistic + structural + outcome signals\n",
    "5. Why this matters for bandit-based rule learning systems\n",
    "\n",
    "Draft for: *\"Here's what everyone gets wrong about evaluating AI agent output\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 workspace\n",
    "draft = \"\"\"\n",
    "# Here's What Everyone Gets Wrong About Evaluating AI Agent Output\n",
    "\n",
    "TODO: Write your draft here.\n",
    "\"\"\"\n",
    "print(draft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# OUTRO\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "## What Just Happened\n",
    "\n",
    "You built a salience scorer that replaces blind substring matching with three\n",
    "targeted signals:\n",
    "\n",
    "- **Linguistic**: Does the output speak the rule's language?\n",
    "- **Structural**: Does the output follow the rule's prescribed pattern?\n",
    "- **Outcome**: Did the task succeed?\n",
    "\n",
    "Combined with configurable weights (`S = w_l * linguistic + w_s * structural +\n",
    "w_o * outcome`), this gives the bandit a dramatically better reward signal.\n",
    "\n",
    "You also established three constitutional rules for the entire arc:\n",
    "\n",
    "1. Every scoring function must have a falsifiable claim\n",
    "2. Weights must be updatable from data, not hardcoded forever\n",
    "3. If you can't explain what a score of 0.7 means in plain English, the scorer isn't ready\n",
    "\n",
    "## Publication Note\n",
    "\n",
    "Exercise 3 is a draft for *\"Here's what everyone gets wrong about evaluating\n",
    "AI agent output.\"* Run an edit pass and it's ready to publish.\n",
    "\n",
    "## What's Next\n",
    "\n",
    "The weights are hand-picked. Why 0.4/0.4/0.2? Because it felt right. That's\n",
    "not science. In Module 0.2, we build the probability foundations to make this\n",
    "rigorous \u2014 so the weights can be learned from data instead of vibes.\n",
    "\n",
    "--> [Module 0.2: Probability & Counting](../module-0.2-probability-counting/0.2-probability-counting-core.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# RESOURCES\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "- **Salience (cognitive science)**: Salience as attention-weighted relevance comes\n",
    "  from cognitive/perceptual psychology. Our scorer approximates what a human\n",
    "  reviewer does intuitively.\n",
    "- **Weighted linear combinations**: Any introductory linear algebra text covers\n",
    "  why this is the simplest useful model. We'll formalize this in Arc 1.\n",
    "- **From the archive**: `archive/v1-week-based/notebooks/` \u2014 earlier explorations\n",
    "  of the bandit that this module's scorer feeds into.\n",
    "- **Blitzstein & Hwang, *Introduction to Probability***: Ch. 1-2 set up the\n",
    "  probability framework we'll use starting in Module 0.2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}